{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT ALL FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_16571/3653438741.py:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(file1_path)\n",
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_16571/3653438741.py:9: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(file2_path)\n",
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_16571/3653438741.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv(file3_path)\n",
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_16571/3653438741.py:11: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4 = pd.read_csv(file4_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1_path = '../../../CSVs/Final/ODI/career_odi.csv'\n",
    "file2_path = '../../../CSVs/Final/ODI/recent_odi.csv'\n",
    "file3_path = '../../../CSVs/Final/ODI/venue_odi.csv'\n",
    "file4_path = '../../../CSVs/Final/ODI/player_match_data_odi.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "df3 = pd.read_csv(file3_path)\n",
    "df4 = pd.read_csv(file4_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10248 entries, 0 to 10247\n",
      "Data columns (total 44 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   match_id                          10248 non-null  object \n",
      " 1   player_id                         10248 non-null  object \n",
      " 2   career_batsman_100s_odi           10248 non-null  int64  \n",
      " 3   career_batsman_50s_odi            10248 non-null  int64  \n",
      " 4   career_batsman_average_runs_odi   10248 non-null  float64\n",
      " 5   career_batsman_strike_rate_odi    10248 non-null  float64\n",
      " 6   career_batsman_total_runs_odi     10248 non-null  int64  \n",
      " 7   career_bowler_average_odi         10248 non-null  float64\n",
      " 8   career_bowler_economy_rate_odi    10248 non-null  float64\n",
      " 9   career_bowler_wickets_odi         10248 non-null  int64  \n",
      " 10  career_fielder_total_catches_odi  10248 non-null  int64  \n",
      " 11  career_fielder_total_runouts_odi  10248 non-null  int64  \n",
      " 12  career_batsman_total_fours_odi    10248 non-null  int64  \n",
      " 13  career_batsman_total_sixes_odi    10248 non-null  int64  \n",
      " 14  recent_batsman_total_runs_odi     10248 non-null  int64  \n",
      " 15  recent_batsman_average_runs_odi   10248 non-null  float64\n",
      " 16  recent_batsman_strike_rate_odi    10248 non-null  float64\n",
      " 17  recent_batsman_total_fours_odi    10248 non-null  int64  \n",
      " 18  recent_batsman_total_sixes_odi    10248 non-null  int64  \n",
      " 19  recent_batsman_50s_odi            10248 non-null  int64  \n",
      " 20  recent_batsman_100s_odi           10248 non-null  int64  \n",
      " 21  recent_bowler_economy_rate_odi    10248 non-null  float64\n",
      " 22  recent_bowler_average_odi         10248 non-null  float64\n",
      " 23  recent_bowler_wickets_odi         10248 non-null  int64  \n",
      " 24  recent_fielder_total_catches_odi  10248 non-null  int64  \n",
      " 25  recent_fielder_total_runouts_odi  10248 non-null  int64  \n",
      " 26  venue_batsman_100s_odi            10248 non-null  int64  \n",
      " 27  venue_batsman_50s_odi             10248 non-null  int64  \n",
      " 28  venue_batsman_average_runs_odi    10248 non-null  float64\n",
      " 29  venue_batsman_strike_rate_odi     10248 non-null  float64\n",
      " 30  venue_batsman_total_runs_odi      10248 non-null  int64  \n",
      " 31  venue_bowler_average_odi          10248 non-null  float64\n",
      " 32  venue_bowler_economy_rate_odi     10248 non-null  float64\n",
      " 33  venue_bowler_wickets_odi          10248 non-null  int64  \n",
      " 34  venue_fielder_total_catches_odi   10248 non-null  int64  \n",
      " 35  venue_fielder_total_runouts_odi   10248 non-null  int64  \n",
      " 36  venue_batsman_total_fours_odi     10248 non-null  int64  \n",
      " 37  venue_batsman_total_sixes_odi     10248 non-null  int64  \n",
      " 38  player_name                       10248 non-null  object \n",
      " 39  fantasy_points                    10248 non-null  int64  \n",
      " 40  team_name                         10060 non-null  object \n",
      " 41  role                              10248 non-null  object \n",
      " 42  date                              10248 non-null  object \n",
      " 43  venue                             10248 non-null  object \n",
      "dtypes: float64(12), int64(25), object(7)\n",
      "memory usage: 3.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Perform the inner merge on 'match_id' and 'player_id' for all four DataFrames\n",
    "merged_df = pd.merge(df1, df2, on=['match_id', 'player_id'], how='inner')\n",
    "merged_df = pd.merge(merged_df, df3, on=['match_id', 'player_id'], how='inner')\n",
    "merged_df = pd.merge(merged_df, df4, on=['match_id', 'player_id'], how='inner')\n",
    "\n",
    "# The final DataFrame after all merges\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "\n",
    "# Split the DataFrame based on the condition (date <= June 30, 2024)\n",
    "split_date = pd.to_datetime('2024-06-30')\n",
    "\n",
    "merged_df_before_june = merged_df[merged_df['date'] <= split_date]\n",
    "merged_df_after_june = merged_df[merged_df['date'] > split_date]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>career_batsman_100s_odi</th>\n",
       "      <th>career_batsman_50s_odi</th>\n",
       "      <th>career_batsman_average_runs_odi</th>\n",
       "      <th>career_batsman_strike_rate_odi</th>\n",
       "      <th>career_batsman_total_runs_odi</th>\n",
       "      <th>career_bowler_average_odi</th>\n",
       "      <th>career_bowler_economy_rate_odi</th>\n",
       "      <th>career_bowler_wickets_odi</th>\n",
       "      <th>...</th>\n",
       "      <th>venue_fielder_total_catches_odi</th>\n",
       "      <th>venue_fielder_total_runouts_odi</th>\n",
       "      <th>venue_batsman_total_fours_odi</th>\n",
       "      <th>venue_batsman_total_sixes_odi</th>\n",
       "      <th>player_name</th>\n",
       "      <th>fantasy_points</th>\n",
       "      <th>team_name</th>\n",
       "      <th>role</th>\n",
       "      <th>date</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1127764</td>\n",
       "      <td>4ec07775</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>49.968750</td>\n",
       "      <td>94.896142</td>\n",
       "      <td>1599</td>\n",
       "      <td>6.014207</td>\n",
       "      <td>36.285714</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RN ten Doeschate</td>\n",
       "      <td>23</td>\n",
       "      <td>Essex</td>\n",
       "      <td>All-Rounder</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>Radlett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1127764</td>\n",
       "      <td>025a092b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>73.584906</td>\n",
       "      <td>39</td>\n",
       "      <td>4.708333</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>RH Patel</td>\n",
       "      <td>88</td>\n",
       "      <td>Middlesex</td>\n",
       "      <td>Bowler</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>Radlett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1127764</td>\n",
       "      <td>cf494ffe</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>30.027778</td>\n",
       "      <td>90.460251</td>\n",
       "      <td>2162</td>\n",
       "      <td>5.164410</td>\n",
       "      <td>49.444444</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PR Stirling</td>\n",
       "      <td>4</td>\n",
       "      <td>Middlesex</td>\n",
       "      <td>All-Rounder</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>Radlett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1127764</td>\n",
       "      <td>c1a89821</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>32.956522</td>\n",
       "      <td>89.071680</td>\n",
       "      <td>758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NRT Gubbins</td>\n",
       "      <td>66</td>\n",
       "      <td>Middlesex</td>\n",
       "      <td>Batsman</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>Radlett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1127764</td>\n",
       "      <td>78adc879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>6.156977</td>\n",
       "      <td>25.214286</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N Wagner</td>\n",
       "      <td>79</td>\n",
       "      <td>Essex</td>\n",
       "      <td>Bowler</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>Radlett</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id player_id  career_batsman_100s_odi  career_batsman_50s_odi  \\\n",
       "0  1127764  4ec07775                        6                      12   \n",
       "1  1127764  025a092b                        0                       0   \n",
       "2  1127764  cf494ffe                        5                      13   \n",
       "3  1127764  c1a89821                        2                       5   \n",
       "4  1127764  78adc879                        0                       0   \n",
       "\n",
       "   career_batsman_average_runs_odi  career_batsman_strike_rate_odi  \\\n",
       "0                        49.968750                       94.896142   \n",
       "1                        13.000000                       73.584906   \n",
       "2                        30.027778                       90.460251   \n",
       "3                        32.956522                       89.071680   \n",
       "4                         7.000000                       50.000000   \n",
       "\n",
       "   career_batsman_total_runs_odi  career_bowler_average_odi  \\\n",
       "0                           1599                   6.014207   \n",
       "1                             39                   4.708333   \n",
       "2                           2162                   5.164410   \n",
       "3                            758                   0.000000   \n",
       "4                              7                   6.156977   \n",
       "\n",
       "   career_bowler_economy_rate_odi  career_bowler_wickets_odi  ...  \\\n",
       "0                       36.285714                         35  ...   \n",
       "1                       45.200000                         10  ...   \n",
       "2                       49.444444                         27  ...   \n",
       "3                        0.000000                          0  ...   \n",
       "4                       25.214286                         14  ...   \n",
       "\n",
       "   venue_fielder_total_catches_odi  venue_fielder_total_runouts_odi  \\\n",
       "0                                0                                0   \n",
       "1                                0                                0   \n",
       "2                                0                                0   \n",
       "3                                3                                0   \n",
       "4                                0                                0   \n",
       "\n",
       "   venue_batsman_total_fours_odi  venue_batsman_total_sixes_odi  \\\n",
       "0                              0                              0   \n",
       "1                              1                              0   \n",
       "2                              0                              0   \n",
       "3                              3                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "        player_name  fantasy_points  team_name         role       date  \\\n",
       "0  RN ten Doeschate              23      Essex  All-Rounder 2018-05-17   \n",
       "1          RH Patel              88  Middlesex       Bowler 2018-05-17   \n",
       "2       PR Stirling               4  Middlesex  All-Rounder 2018-05-17   \n",
       "3       NRT Gubbins              66  Middlesex      Batsman 2018-05-17   \n",
       "4          N Wagner              79      Essex       Bowler 2018-05-17   \n",
       "\n",
       "     venue  \n",
       "0  Radlett  \n",
       "1  Radlett  \n",
       "2  Radlett  \n",
       "3  Radlett  \n",
       "4  Radlett  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_before_june.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['match_id', 'player_id', 'career_batsman_100s_odi', 'career_batsman_50s_odi', 'career_batsman_average_runs_odi', 'career_batsman_strike_rate_odi', 'career_batsman_total_runs_odi', 'career_bowler_average_odi', 'career_bowler_economy_rate_odi', 'career_bowler_wickets_odi', 'career_fielder_total_catches_odi', 'career_fielder_total_runouts_odi', 'career_batsman_total_fours_odi', 'career_batsman_total_sixes_odi', 'recent_batsman_total_runs_odi', 'recent_batsman_average_runs_odi', 'recent_batsman_strike_rate_odi', 'recent_batsman_total_fours_odi', 'recent_batsman_total_sixes_odi', 'recent_batsman_50s_odi', 'recent_batsman_100s_odi', 'recent_bowler_economy_rate_odi', 'recent_bowler_average_odi', 'recent_bowler_wickets_odi', 'recent_fielder_total_catches_odi', 'recent_fielder_total_runouts_odi', 'venue_batsman_100s_odi', 'venue_batsman_50s_odi', 'venue_batsman_average_runs_odi', 'venue_batsman_strike_rate_odi', 'venue_batsman_total_runs_odi', 'venue_bowler_average_odi', 'venue_bowler_economy_rate_odi', 'venue_bowler_wickets_odi', 'venue_fielder_total_catches_odi', 'venue_fielder_total_runouts_odi', 'venue_batsman_total_fours_odi', 'venue_batsman_total_sixes_odi', 'player_name', 'fantasy_points', 'team_name', 'role', 'date', 'venue']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of columns in merged_df_before_june\n",
    "columns_list = merged_df_before_june.columns.tolist()\n",
    "\n",
    "# Print the list of columns\n",
    "print(columns_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match id , player id, player name, fantasy points, team name, role, date \n",
    "drop all the fields mentioned above in merged_df_before_june\n",
    "except these features everything in merged_df_before_june dataframe is Xtrain, Y train is fantasy_points\n",
    "\n",
    "except these features everything in merged_df_after_june dataframe is Ytrain, Y train is fantasy_points \n",
    "\n",
    "train model in huber regression of scikit learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients: [ 0.15649447  0.02148526  0.07704909  0.05134998 -0.0120267   0.82674524\n",
      " -0.06313978  0.03940587  0.17564732 -0.25165269  0.13561236 -0.14567902\n",
      "  0.0505908   0.0860646   0.06850156 -0.09888726 -0.22385939 -0.05206217\n",
      " -0.00860761  1.25137859  0.09833882  2.34319072  0.16325804  0.01756129\n",
      " -0.00696275  0.01032885  0.05324316 -0.0045383   0.00522954 -0.08627601\n",
      "  0.4071419   0.54324534  0.1812351   0.01329856 -0.0630627   0.02709884]\n",
      "Model intercept: 0.46464249863854085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Drop columns that are not part of X_train\n",
    "columns_to_drop = ['match_id', 'player_id', 'player_name', 'fantasy_points', 'team_name', 'role', 'date','venue']\n",
    "X_train = merged_df_before_june.drop(columns=columns_to_drop)\n",
    "\n",
    "# Extract the target variable (fantasy_points)\n",
    "y_train = merged_df_before_june['fantasy_points']\n",
    "\n",
    "# # Standardize the features (mean=0, std=1)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize the Huber Regressor model\n",
    "model = HuberRegressor()\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# After training, you can check the coefficients and intercept\n",
    "print(f\"Model coefficients: {model.coef_}\")\n",
    "print(f\"Model intercept: {model.intercept_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 36)) while a minimum of 1 is required by HuberRegressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m y_test \u001b[39m=\u001b[39m merged_df_after_june[\u001b[39m'\u001b[39m\u001b[39mfantasy_points\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39m# # Initialize the StandardScaler\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# scaler = StandardScaler()\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[39m# Use the trained model to make predictions on the test data\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     15\u001b[0m \u001b[39m# You can now compare y_pred with y_test to evaluate the model's performance\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_base.py:306\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    293\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_base.py:285\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    283\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 285\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    286\u001b[0m     coef_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\n\u001b[1;32m    287\u001b[0m     \u001b[39mif\u001b[39;00m coef_\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:1087\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1086\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1087\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1088\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1089\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1091\u001b[0m         )\n\u001b[1;32m   1093\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1094\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 36)) while a minimum of 1 is required by HuberRegressor."
     ]
    }
   ],
   "source": [
    "# X_test and y_test for merged_df_after_june\n",
    "X_test = merged_df_after_june.drop(columns=columns_to_drop)\n",
    "y_test = merged_df_after_june['fantasy_points']\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# # Transform X_test with the already fitted scaler\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# You can now compare y_pred with y_test to evaluate the model's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 36)) while a minimum of 1 is required by HuberRegressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Make predictions on X_test\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Create a new DataFrame with the necessary columns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions_df \u001b[39m=\u001b[39m merged_df_after_june[[\u001b[39m'\u001b[39m\u001b[39mmatch_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mplayer_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mplayer_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfantasy_points\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mteam_name\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_base.py:306\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    293\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_base.py:285\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    283\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 285\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    286\u001b[0m     coef_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\n\u001b[1;32m    287\u001b[0m     \u001b[39mif\u001b[39;00m coef_\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:1087\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1086\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1087\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1088\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1089\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1091\u001b[0m         )\n\u001b[1;32m   1093\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1094\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 36)) while a minimum of 1 is required by HuberRegressor."
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on X_test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a new DataFrame with the necessary columns\n",
    "predictions_df = merged_df_after_june[['match_id', 'player_id', 'player_name', 'fantasy_points', 'role', 'team_name']].copy()\n",
    "\n",
    "# Add the predicted fantasy points to the DataFrame\n",
    "predictions_df['predicted_fantasy_points'] = y_pred\n",
    "\n",
    "# Rename the fantasy_points column to actual_fantasy_points\n",
    "predictions_df.rename(columns={'fantasy_points': 'actual_fantasy_points'}, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = \"Results/predicted_fantasy_points_odi.csv\"  # You can change the file path as needed\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 matches...\n",
      "Processed 200 matches...\n",
      "Dream Team details saved to Results/dream_team_with_predicted_fantasy_points.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input File (Predicted Fantasy Points)\n",
    "input_file = \"Results/predicted_fantasy_points_odi.csv\"\n",
    "\n",
    "# Output File\n",
    "output_file = \"Results/dream_team_with_predicted_fantasy_points.csv\"\n",
    "\n",
    "# Columns for Output\n",
    "output_columns = [\n",
    "    \"match_id\", \"player_id\", \"player_name\", \"actual_fantasy_points\", \"role\", \"team_name\", \"predicted_fantasy_points\"\n",
    "]\n",
    "\n",
    "# Read Data\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Prepare Output Data\n",
    "output_data = []\n",
    "\n",
    "# Define Dream Team Calculation Logic\n",
    "def calculate_dream_team(players):\n",
    "    try:\n",
    "        # Step 1: Pick one player from each role based on predicted fantasy points\n",
    "        selected_players = []\n",
    "        for role in [\"Batsman\", \"Bowler\", \"Wicket-Keeper\", \"All-Rounder\"]:\n",
    "            role_players = [p for p in players if p[\"role\"] == role]\n",
    "            if role_players:\n",
    "                selected_players.append(max(role_players, key=lambda x: x[\"predicted_fantasy_points\"]))\n",
    "\n",
    "        # Step 2: Select remaining players to make a team of 11\n",
    "        remaining_players = [p for p in players if p not in selected_players]\n",
    "        remaining_players.sort(key=lambda x: x[\"predicted_fantasy_points\"], reverse=True)\n",
    "\n",
    "        while len(selected_players) < 11:\n",
    "            next_player = remaining_players.pop(0)\n",
    "            selected_players.append(next_player)\n",
    "\n",
    "        # Step 3: Ensure team diversity (max 5 players from one team)\n",
    "        team_counts = pd.DataFrame(selected_players)[\"team_name\"].value_counts()\n",
    "        if team_counts.max() == 11:\n",
    "            # Replace the lowest fantasy point player with the highest fantasy point player from the other team\n",
    "            other_team = [team for team in players[0][\"team_name\"].unique() if team not in team_counts.index][0]\n",
    "            lowest_fantasy_player = min(selected_players, key=lambda x: x[\"predicted_fantasy_points\"])\n",
    "            replacement_player = max(\n",
    "                [p for p in players if p[\"team_name\"] == other_team and p not in selected_players],\n",
    "                key=lambda x: x[\"predicted_fantasy_points\"]\n",
    "            )\n",
    "            selected_players.remove(lowest_fantasy_player)\n",
    "            selected_players.append(replacement_player)\n",
    "\n",
    "        # Step 4: Sort selected players by predicted fantasy points\n",
    "        selected_players.sort(key=lambda x: x[\"predicted_fantasy_points\"], reverse=True)\n",
    "\n",
    "        return selected_players, \"Optimal\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculating dream team: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "# Process Matches\n",
    "i = 1\n",
    "for match_id, match_group in data.groupby(\"match_id\"):\n",
    "    # Extract only necessary columns (player_id, role, team_name, predicted_fantasy_points)\n",
    "    players = match_group[['match_id', 'player_id', 'player_name', 'actual_fantasy_points', 'role', 'team_name', 'predicted_fantasy_points']].to_dict(orient=\"records\")\n",
    "    \n",
    "    # Calculate Dream Team\n",
    "    selected_team, status = calculate_dream_team(players)\n",
    "\n",
    "    if selected_team is None or len(selected_team) != 11:\n",
    "        # If selected_team is None or doesn't have exactly 11 players, log the error\n",
    "        with open(\"matches_where_team_could_not_be_formed.txt\", 'a') as file:\n",
    "            file.write(f\"{status}, {match_id}, {len(selected_team) if selected_team else 'None'}, {selected_team if selected_team else 'None'}\\n\")\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # Prepare Row for Output\n",
    "    for player in selected_team:\n",
    "        row = [\n",
    "            match_id,\n",
    "            player[\"player_id\"],\n",
    "            player[\"player_name\"],\n",
    "            player[\"actual_fantasy_points\"],\n",
    "            player[\"role\"],\n",
    "            player[\"team_name\"],\n",
    "            player[\"predicted_fantasy_points\"]\n",
    "        ]\n",
    "        output_data.append(row)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i} matches...\")\n",
    "    i += 1\n",
    "\n",
    "# Write Output to CSV\n",
    "output_df = pd.DataFrame(output_data, columns=output_columns)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dream Team details saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 matches...\n",
      "Processed 200 matches...\n",
      "Dream Team details saved to Results/dream_team_with_actual_fantasy_points.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input File (Predicted Fantasy Points)\n",
    "input_file = \"Results/predicted_fantasy_points_odi.csv\"\n",
    "\n",
    "# Output File\n",
    "output_file = \"Results/dream_team_with_actual_fantasy_points.csv\"\n",
    "\n",
    "# Columns for Output\n",
    "output_columns = [\n",
    "    \"match_id\", \"player_id\", \"player_name\", \"actual_fantasy_points\", \"role\", \"team_name\", \"predicted_fantasy_points\"\n",
    "]\n",
    "\n",
    "# Read Data\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Prepare Output Data\n",
    "output_data = []\n",
    "\n",
    "# Define Dream Team Calculation Logic\n",
    "def calculate_dream_team(players):\n",
    "    try:\n",
    "        # Step 1: Pick one player from each role based on predicted fantasy points\n",
    "        selected_players = []\n",
    "        for role in [\"Batsman\", \"Bowler\", \"Wicket-Keeper\", \"All-Rounder\"]:\n",
    "            role_players = [p for p in players if p[\"role\"] == role]\n",
    "            if role_players:\n",
    "                selected_players.append(max(role_players, key=lambda x: x[\"actual_fantasy_points\"]))\n",
    "\n",
    "        # Step 2: Select remaining players to make a team of 11\n",
    "        remaining_players = [p for p in players if p not in selected_players]\n",
    "        remaining_players.sort(key=lambda x: x[\"actual_fantasy_points\"], reverse=True)\n",
    "\n",
    "        while len(selected_players) < 11:\n",
    "            next_player = remaining_players.pop(0)\n",
    "            selected_players.append(next_player)\n",
    "\n",
    "        # Step 3: Ensure team diversity (max 5 players from one team)\n",
    "        team_counts = pd.DataFrame(selected_players)[\"team_name\"].value_counts()\n",
    "        if team_counts.max() == 11:\n",
    "            # Replace the lowest fantasy point player with the highest fantasy point player from the other team\n",
    "            other_team = [team for team in players[0][\"team_name\"].unique() if team not in team_counts.index][0]\n",
    "            lowest_fantasy_player = min(selected_players, key=lambda x: x[\"actual_fantasy_points\"])\n",
    "            replacement_player = max(\n",
    "                [p for p in players if p[\"team_name\"] == other_team and p not in selected_players],\n",
    "                key=lambda x: x[\"actual_fantasy_points\"]\n",
    "            )\n",
    "            selected_players.remove(lowest_fantasy_player)\n",
    "            selected_players.append(replacement_player)\n",
    "\n",
    "        # Step 4: Sort selected players by actual fantasy points\n",
    "        selected_players.sort(key=lambda x: x[\"actual_fantasy_points\"], reverse=True)\n",
    "\n",
    "        return selected_players, \"Optimal\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculating dream team: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "# Process Matches\n",
    "i = 1\n",
    "for match_id, match_group in data.groupby(\"match_id\"):\n",
    "    # Extract only necessary columns (player_id, role, team_name, predicted_fantasy_points)\n",
    "    players = match_group[['match_id', 'player_id', 'player_name', 'actual_fantasy_points', 'role', 'team_name', 'predicted_fantasy_points']].to_dict(orient=\"records\")\n",
    "    \n",
    "    # Calculate Dream Team\n",
    "    selected_team, status = calculate_dream_team(players)\n",
    "\n",
    "    if selected_team is None or len(selected_team) != 11:\n",
    "        # If selected_team is None or doesn't have exactly 11 players, log the error\n",
    "        with open(\"matches_where_team_could_not_be_formed.txt\", 'a') as file:\n",
    "            file.write(f\"{status}, {match_id}, {len(selected_team) if selected_team else 'None'}, {selected_team if selected_team else 'None'}\\n\")\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # Prepare Row for Output\n",
    "    for player in selected_team:\n",
    "        row = [\n",
    "            match_id,\n",
    "            player[\"player_id\"],\n",
    "            player[\"player_name\"],\n",
    "            player[\"actual_fantasy_points\"],\n",
    "            player[\"role\"],\n",
    "            player[\"team_name\"],\n",
    "            player[\"predicted_fantasy_points\"]\n",
    "        ]\n",
    "        output_data.append(row)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i} matches...\")\n",
    "    i += 1\n",
    "\n",
    "# Write Output to CSV\n",
    "output_df = pd.DataFrame(output_data, columns=output_columns)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dream Team details saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARISION OF PREDICTED AND ACTUAL DREAM TEAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dream-11/Code/Model_Final/Results/dream_team_with_predicted_fantasy_points.csv\n",
    "\n",
    "\n",
    "Dream-11/Code/Model_Final/Results/dream_team_with_actual_fantasy_points.csv\n",
    "\n",
    "in both these files match_id,player_id,player_name,actual_fantasy_points,role,team_name,predicted_fantasy_points\n",
    "\n",
    "generate a new csv with match id , sum of actual points of predicted dream team, sum of predicted points of predicted dream team , sum of actual points of actual dream team, sum of predicted points of actual dream team\n",
    "\n",
    "for sum of points in both the cases multiply the highest points by 2 and second highest by 1.5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to Results/dream_team_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths for the input files\n",
    "predicted_file = \"Results/dream_team_with_predicted_fantasy_points.csv\"\n",
    "actual_file = \"Results/dream_team_with_actual_fantasy_points.csv\"\n",
    "\n",
    "# Output file path\n",
    "output_file = \"Results/dream_team_summary.csv\"\n",
    "\n",
    "# Read the data from the two files\n",
    "predicted_df = pd.read_csv(predicted_file)\n",
    "actual_df = pd.read_csv(actual_file)\n",
    "\n",
    "# Initialize list to store the summary for each match_id\n",
    "summary_data = []\n",
    "\n",
    "# Function to calculate the sum of fantasy points (with captain and vice-captain multipliers)\n",
    "def calculate_team_points(team_df):\n",
    "    team_df = team_df.sort_values(by='predicted_fantasy_points', ascending=False)  # Sort by predicted points (or actual, depending on case)\n",
    "    \n",
    "    total_points = 0\n",
    "    if len(team_df) >= 1:\n",
    "        # Highest points player (Captain)\n",
    "        total_points += team_df.iloc[0]['predicted_fantasy_points'] * 2\n",
    "    if len(team_df) >= 2:\n",
    "        # Second highest points player (Vice-Captain)\n",
    "        total_points += team_df.iloc[1]['predicted_fantasy_points'] * 1.5\n",
    "    \n",
    "    # Add the rest normally\n",
    "    total_points += team_df.iloc[2:]['predicted_fantasy_points'].sum()\n",
    "\n",
    "    return total_points\n",
    "\n",
    "# Iterate through the unique match IDs\n",
    "for match_id in predicted_df['match_id'].unique():\n",
    "    # Get the predicted dream team for the current match_id\n",
    "    predicted_team = predicted_df[predicted_df['match_id'] == match_id]\n",
    "\n",
    "    # Get the actual dream team for the current match_id\n",
    "    actual_team = actual_df[actual_df['match_id'] == match_id]\n",
    "\n",
    "    # Calculate the sum of actual and predicted points for both teams\n",
    "    predicted_team_points = calculate_team_points(predicted_team)\n",
    "    actual_team_points_predicted = calculate_team_points(actual_team)\n",
    "    \n",
    "    # Add the match summary to the summary_data list\n",
    "    summary_data.append({\n",
    "        'match_id': match_id,\n",
    "        'sum_predicted_points_predicted_team': predicted_team_points,\n",
    "        'sum_predicted_points_actual_team': actual_team_points_predicted,\n",
    "        'sum_actual_points_predicted_team': predicted_team['actual_fantasy_points'].sum(),\n",
    "        'sum_actual_points_actual_team': actual_team['actual_fantasy_points'].sum()\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the summary_data\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Write the summary data to a CSV file\n",
    "summary_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Summary saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Errors for each match:\n",
      "     match_id  %error_predicted_actual  %error_predicted_predicted\n",
      "0     1385700                42.913001                   44.128148\n",
      "1     1385701                46.906637                   31.844574\n",
      "2     1385702                43.287037                   35.250207\n",
      "3     1385703                37.818182                   25.525556\n",
      "4     1385704                40.338983                   37.927539\n",
      "..        ...                      ...                         ...\n",
      "208   1457465                30.813953                   40.145558\n",
      "209   1457466                38.546603                    5.470502\n",
      "210   1457467                25.652842                   23.858335\n",
      "211   1457468                20.471464                   33.201024\n",
      "212   1457469                27.737226                   31.737983\n",
      "\n",
      "[213 rows x 3 columns]\n",
      "\n",
      "Mean % error between predicted team actual points and actual team actual points: 32.90%\n",
      "Mean % error between predicted team predicted points and actual team actual points: 44.87%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dream_team_summary.csv file into a DataFrame\n",
    "summary_file = \"Results/dream_team_summary.csv\"\n",
    "df = pd.read_csv(summary_file)\n",
    "\n",
    "# Calculate the percentage errors for each match\n",
    "df['%error_predicted_actual'] = abs(df['sum_actual_points_predicted_team'] - df['sum_actual_points_actual_team']) / df['sum_actual_points_actual_team'] * 100\n",
    "df['%error_predicted_predicted'] = abs(df['sum_predicted_points_predicted_team'] - df['sum_actual_points_actual_team']) / df['sum_actual_points_actual_team'] * 100\n",
    "\n",
    "# Print the results with the percentage errors\n",
    "print(\"Percentage Errors for each match:\")\n",
    "print(df[['match_id', '%error_predicted_actual', '%error_predicted_predicted']])\n",
    "\n",
    "# Calculate the mean of the percentage errors\n",
    "mean_error_predicted_actual = df['%error_predicted_actual'].mean()\n",
    "mean_error_predicted_predicted = df['%error_predicted_predicted'].mean()\n",
    "\n",
    "# Print the mean errors\n",
    "print(f\"\\nMean % error between predicted team actual points and actual team actual points: {mean_error_predicted_actual:.2f}%\")\n",
    "print(f\"Mean % error between predicted team predicted points and actual team actual points: {mean_error_predicted_predicted:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Errors for each match:\n",
      "     match_id  %error_predicted_actual  %error_predicted_predicted\n",
      "0     1385700                42.913001                   44.128148\n",
      "1     1385701                46.906637                   31.844574\n",
      "2     1385702                43.287037                   35.250207\n",
      "3     1385703                37.818182                   25.525556\n",
      "4     1385704                40.338983                   37.927539\n",
      "..        ...                      ...                         ...\n",
      "208   1457465                30.813953                   40.145558\n",
      "209   1457466                38.546603                    5.470502\n",
      "210   1457467                25.652842                   23.858335\n",
      "211   1457468                20.471464                   33.201024\n",
      "212   1457469                27.737226                   31.737983\n",
      "\n",
      "[213 rows x 3 columns]\n",
      "\n",
      "Mean % error between predicted team actual points and actual team actual points: 32.90%\n",
      "Mean % error between predicted team predicted points and actual team actual points: 44.87%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dream_team_summary.csv file into a DataFrame\n",
    "summary_file = \"Results/dream_team_summary.csv\"\n",
    "df = pd.read_csv(summary_file)\n",
    "\n",
    "# Calculate the percentage errors for each match\n",
    "df['%error_predicted_actual'] = abs(df['sum_actual_points_predicted_team'] - df['sum_actual_points_actual_team']) / df['sum_actual_points_actual_team'] * 100\n",
    "df['%error_predicted_predicted'] = abs(df['sum_predicted_points_predicted_team'] - df['sum_actual_points_actual_team']) / df['sum_actual_points_actual_team'] * 100\n",
    "\n",
    "# Calculate the mean of the percentage errors\n",
    "mean_error_predicted_actual = df['%error_predicted_actual'].mean()\n",
    "mean_error_predicted_predicted = df['%error_predicted_predicted'].mean()\n",
    "\n",
    "# Print the results with the percentage errors\n",
    "print(\"Percentage Errors for each match:\")\n",
    "print(df[['match_id', '%error_predicted_actual', '%error_predicted_predicted']])\n",
    "\n",
    "# Print the mean errors\n",
    "print(f\"\\nMean % error between predicted team actual points and actual team actual points: {mean_error_predicted_actual:.2f}%\")\n",
    "print(f\"Mean % error between predicted team predicted points and actual team actual points: {mean_error_predicted_predicted:.2f}%\")\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(summary_file, index=False)\n",
    "\n",
    "# Optionally, save to a new file if you don't want to overwrite the original\n",
    "# df.to_csv(\"Results/dream_team_summary_with_errors.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_odi.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'model_odi.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel_odi.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     pickle\u001b[39m.\u001b[39mdump(model, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model_odi.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n",
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "print(joblib.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
