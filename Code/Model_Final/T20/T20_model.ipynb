{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_87294/2008622891.py:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(file1_path)\n",
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_87294/2008622891.py:9: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(file2_path)\n",
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_87294/2008622891.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv(file3_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1_path = '../../../CSVs/Final/T20/career_t20.csv'\n",
    "file2_path = '../../../CSVs/Final/T20/recent_t20.csv'\n",
    "file3_path = '../../../CSVs/Final/T20/venue_t20.csv'\n",
    "file4_path = '../../../CSVs/Final/T20/player_match_data_t20.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "df3 = pd.read_csv(file3_path)\n",
    "\n",
    "df4 = pd.read_csv(file4_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_87294/1048661856.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(file1_path)\n",
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_87294/1048661856.py:5: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(file2_path)\n",
      "/var/folders/fc/m5qlqlv518x0v2g6w7wjsh1w0000gn/T/ipykernel_87294/1048661856.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv(file3_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_id                             object\n",
      "player_id                            object\n",
      "career_batsman_100s_t20               int64\n",
      "career_batsman_50s_t20                int64\n",
      "career_batsman_30s_t20                int64\n",
      "career_batsman_average_runs_t20     float64\n",
      "career_batsman_strike_rate_t20      float64\n",
      "career_batsman_total_runs_t20         int64\n",
      "career_bowler_average_t20           float64\n",
      "career_bowler_economy_rate_t20      float64\n",
      "career_bowler_wickets_t20             int64\n",
      "career_fielder_total_catches_t20      int64\n",
      "career_fielder_total_runouts_t20      int64\n",
      "career_batsman_total_fours_t20        int64\n",
      "career_batsman_total_sixes_t20        int64\n",
      "dtype: object\n",
      "match_id                             object\n",
      "player_id                            object\n",
      "recent_batsman_total_runs_t20         int64\n",
      "recent_batsman_average_runs_t20     float64\n",
      "recent_batsman_strike_rate_t20      float64\n",
      "recent_batsman_total_fours_t20        int64\n",
      "recent_batsman_total_sixes_t20        int64\n",
      "recent_batsman_30s_t20                int64\n",
      "recent_batsman_50s_t20                int64\n",
      "recent_batsman_100s_t20               int64\n",
      "recent_bowler_economy_rate_t20      float64\n",
      "recent_bowler_average_t20           float64\n",
      "recent_bowler_wickets_t20             int64\n",
      "recent_fielder_total_catches_t20      int64\n",
      "recent_fielder_runouts_t20            int64\n",
      "dtype: object\n",
      "match_id                            object\n",
      "player_id                           object\n",
      "venue_batsman_100s_t20               int64\n",
      "venue_batsman_50s_t20                int64\n",
      "venue_batsman_30s_t20                int64\n",
      "venue_batsman_average_runs_t20     float64\n",
      "venue_batsman_strike_rate_t20      float64\n",
      "venue_batsman_total_runs_t20         int64\n",
      "venue_bowler_average_t20           float64\n",
      "venue_bowler_economy_rate_t20      float64\n",
      "venue_bowler_wickets_t20             int64\n",
      "venue_fielder_total_catches_t20      int64\n",
      "venue_fielder_total_runouts_t20      int64\n",
      "venue_batsman_total_fours_t20        int64\n",
      "venue_batsman_total_sixes_t20        int64\n",
      "dtype: object\n",
      "match_id          object\n",
      "player_id         object\n",
      "player_name       object\n",
      "fantasy_points     int64\n",
      "team_name         object\n",
      "role              object\n",
      "date              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "df3 = pd.read_csv(file3_path)\n",
    "df4 = pd.read_csv(file4_path)\n",
    "\n",
    "# Convert 'match_id' and 'player_id' columns to string type\n",
    "df1['match_id'] = df1['match_id'].astype(str)\n",
    "df1['player_id'] = df1['player_id'].astype(str)\n",
    "\n",
    "df2['match_id'] = df2['match_id'].astype(str)\n",
    "df2['player_id'] = df2['player_id'].astype(str)\n",
    "\n",
    "df3['match_id'] = df3['match_id'].astype(str)\n",
    "df3['player_id'] = df3['player_id'].astype(str)\n",
    "\n",
    "df4['match_id'] = df4['match_id'].astype(str)\n",
    "df4['player_id'] = df4['player_id'].astype(str)\n",
    "\n",
    "# Check the data types to confirm\n",
    "print(df1.dtypes)\n",
    "print(df2.dtypes)\n",
    "print(df3.dtypes)\n",
    "print(df4.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286559 entries, 0 to 286558\n",
      "Data columns (total 15 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   match_id                          286559 non-null  object \n",
      " 1   player_id                         286559 non-null  object \n",
      " 2   career_batsman_100s_t20           286559 non-null  int64  \n",
      " 3   career_batsman_50s_t20            286559 non-null  int64  \n",
      " 4   career_batsman_30s_t20            286559 non-null  int64  \n",
      " 5   career_batsman_average_runs_t20   286559 non-null  float64\n",
      " 6   career_batsman_strike_rate_t20    286559 non-null  float64\n",
      " 7   career_batsman_total_runs_t20     286559 non-null  int64  \n",
      " 8   career_bowler_average_t20         286559 non-null  float64\n",
      " 9   career_bowler_economy_rate_t20    286559 non-null  float64\n",
      " 10  career_bowler_wickets_t20         286559 non-null  int64  \n",
      " 11  career_fielder_total_catches_t20  286559 non-null  int64  \n",
      " 12  career_fielder_total_runouts_t20  286559 non-null  int64  \n",
      " 13  career_batsman_total_fours_t20    286559 non-null  int64  \n",
      " 14  career_batsman_total_sixes_t20    286559 non-null  int64  \n",
      "dtypes: float64(4), int64(9), object(2)\n",
      "memory usage: 32.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244772 entries, 0 to 244771\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   match_id        244772 non-null  object\n",
      " 1   player_id       244772 non-null  object\n",
      " 2   player_name     244772 non-null  object\n",
      " 3   fantasy_points  244772 non-null  int64 \n",
      " 4   team_name       241124 non-null  object\n",
      " 5   role            244772 non-null  object\n",
      " 6   date            244772 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 13.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244772"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the inner merge on 'match_id' and 'player_id' for all four DataFrames\n",
    "merged_df = pd.merge(df1, df2, on=['match_id', 'player_id'], how='outer')\n",
    "\n",
    "merged_df = pd.merge(merged_df, df3, on=['match_id', 'player_id'], how='inner')\n",
    "merged_df = pd.merge(merged_df, df4, on=['match_id', 'player_id'], how='inner')\n",
    "\n",
    "# The final DataFrame after all merges\n",
    "merged_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>career_batsman_100s_t20</th>\n",
       "      <th>career_batsman_50s_t20</th>\n",
       "      <th>career_batsman_30s_t20</th>\n",
       "      <th>career_batsman_average_runs_t20</th>\n",
       "      <th>career_batsman_strike_rate_t20</th>\n",
       "      <th>career_batsman_total_runs_t20</th>\n",
       "      <th>career_bowler_average_t20</th>\n",
       "      <th>career_bowler_economy_rate_t20</th>\n",
       "      <th>...</th>\n",
       "      <th>venue_bowler_wickets_t20</th>\n",
       "      <th>venue_fielder_total_catches_t20</th>\n",
       "      <th>venue_fielder_total_runouts_t20</th>\n",
       "      <th>venue_batsman_total_fours_t20</th>\n",
       "      <th>venue_batsman_total_sixes_t20</th>\n",
       "      <th>player_name</th>\n",
       "      <th>fantasy_points</th>\n",
       "      <th>team_name</th>\n",
       "      <th>role</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244767</th>\n",
       "      <td>1454819</td>\n",
       "      <td>d7bfcc0b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.560000</td>\n",
       "      <td>108.144796</td>\n",
       "      <td>239</td>\n",
       "      <td>19.857143</td>\n",
       "      <td>6.707775</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mehran Khan</td>\n",
       "      <td>33</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Bowler</td>\n",
       "      <td>2024-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244768</th>\n",
       "      <td>1454819</td>\n",
       "      <td>60606200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Muzahir Raza</td>\n",
       "      <td>93</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Bowler</td>\n",
       "      <td>2024-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244769</th>\n",
       "      <td>1454819</td>\n",
       "      <td>f427e63e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>102.325581</td>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NRJ Croes</td>\n",
       "      <td>45</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Batsman</td>\n",
       "      <td>2024-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244770</th>\n",
       "      <td>1442670</td>\n",
       "      <td>9c515112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.090909</td>\n",
       "      <td>98.785425</td>\n",
       "      <td>244</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>6.942795</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>LG Smith</td>\n",
       "      <td>25</td>\n",
       "      <td>Hobart Hurricanes</td>\n",
       "      <td>Bowler</td>\n",
       "      <td>2024-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244771</th>\n",
       "      <td>1442670</td>\n",
       "      <td>f13d3eba</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>30.831325</td>\n",
       "      <td>106.536220</td>\n",
       "      <td>2559</td>\n",
       "      <td>21.423729</td>\n",
       "      <td>6.325271</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>KE Bryce</td>\n",
       "      <td>-2</td>\n",
       "      <td>Hobart Hurricanes</td>\n",
       "      <td>All-Rounder</td>\n",
       "      <td>2024-11-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       match_id player_id  career_batsman_100s_t20  career_batsman_50s_t20  \\\n",
       "244767  1454819  d7bfcc0b                        0                       0   \n",
       "244768  1454819  60606200                        0                       0   \n",
       "244769  1454819  f427e63e                        0                       0   \n",
       "244770  1442670  9c515112                        0                       0   \n",
       "244771  1442670  f13d3eba                        0                      18   \n",
       "\n",
       "        career_batsman_30s_t20  career_batsman_average_runs_t20  \\\n",
       "244767                       0                         9.560000   \n",
       "244768                       0                         0.000000   \n",
       "244769                       1                        14.666667   \n",
       "244770                       0                        11.090909   \n",
       "244771                      17                        30.831325   \n",
       "\n",
       "        career_batsman_strike_rate_t20  career_batsman_total_runs_t20  \\\n",
       "244767                      108.144796                            239   \n",
       "244768                        0.000000                              0   \n",
       "244769                      102.325581                             44   \n",
       "244770                       98.785425                            244   \n",
       "244771                      106.536220                           2559   \n",
       "\n",
       "        career_bowler_average_t20  career_bowler_economy_rate_t20  ...  \\\n",
       "244767                  19.857143                        6.707775  ...   \n",
       "244768                   0.000000                        0.000000  ...   \n",
       "244769                   0.000000                        0.000000  ...   \n",
       "244770                  23.500000                        6.942795  ...   \n",
       "244771                  21.423729                        6.325271  ...   \n",
       "\n",
       "        venue_bowler_wickets_t20  venue_fielder_total_catches_t20  \\\n",
       "244767                         8                                4   \n",
       "244768                         0                                0   \n",
       "244769                         0                                0   \n",
       "244770                         5                                1   \n",
       "244771                         0                                1   \n",
       "\n",
       "        venue_fielder_total_runouts_t20  venue_batsman_total_fours_t20  \\\n",
       "244767                                1                              1   \n",
       "244768                                0                              0   \n",
       "244769                                0                              0   \n",
       "244770                                0                              2   \n",
       "244771                                0                              0   \n",
       "\n",
       "        venue_batsman_total_sixes_t20   player_name  fantasy_points  \\\n",
       "244767                              3   Mehran Khan              33   \n",
       "244768                              0  Muzahir Raza              93   \n",
       "244769                              0     NRJ Croes              45   \n",
       "244770                              1      LG Smith              25   \n",
       "244771                              0      KE Bryce              -2   \n",
       "\n",
       "                team_name         role        date  \n",
       "244767               Oman       Bowler  2024-11-13  \n",
       "244768               Oman       Bowler  2024-11-13  \n",
       "244769        Netherlands      Batsman  2024-11-13  \n",
       "244770  Hobart Hurricanes       Bowler  2024-11-13  \n",
       "244771  Hobart Hurricanes  All-Rounder  2024-11-13  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "\n",
    "# Split the DataFrame based on the condition (date <= June 30, 2024)\n",
    "split_date = pd.to_datetime('2024-06-30')\n",
    "\n",
    "merged_df_before_june = merged_df[merged_df['date'] <= split_date]\n",
    "merged_df_after_june = merged_df[merged_df['date'] > split_date]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients: [ 4.81137604e-02  2.31082176e-01 -1.20553563e-01  6.32153382e-02\n",
      "  4.36801495e-02 -1.41332131e-03 -8.58326698e-02  6.18015531e-01\n",
      "  2.39524490e-03  3.56596815e-03  3.44196718e-01  1.18923079e-02\n",
      " -4.91521467e-04  6.04418531e-02  8.39045400e-02  6.77210503e-03\n",
      "  1.04033841e-01 -1.43110131e-01 -1.55537822e-02 -1.10517206e-02\n",
      " -1.65013211e-03  8.11292673e-01  1.09141432e-01  1.71957028e+00\n",
      "  2.01469670e-01  1.04249230e-01  2.86118186e-03  2.43208600e-02\n",
      " -1.89603321e-02 -2.84629907e-02  2.48637759e-03 -3.09296159e-03\n",
      " -1.56821292e-01  2.97542427e-01  3.94313661e-01  4.22420785e-02\n",
      "  4.68289579e-02  1.11180403e-01 -3.57910098e-02]\n",
      "Model intercept: 0.36582289466649626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Drop columns that are not part of X_train\n",
    "columns_to_drop = ['match_id', 'player_id', 'player_name', 'fantasy_points', 'team_name', 'role', 'date']\n",
    "X_train = merged_df_before_june.drop(columns=columns_to_drop)\n",
    "\n",
    "# Extract the target variable (fantasy_points)\n",
    "y_train = merged_df_before_june['fantasy_points']\n",
    "\n",
    "# # Standardize the features (mean=0, std=1)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize the Huber Regressor model\n",
    "model = HuberRegressor()\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# After training, you can check the coefficients and intercept\n",
    "print(f\"Model coefficients: {model.coef_}\")\n",
    "print(f\"Model intercept: {model.intercept_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# List of models to compare\n",
    "models = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Lasso Regression\", Lasso()),\n",
    "    (\"Ridge Regression\", Ridge()),\n",
    "    (\"Decision Tree\", DecisionTreeRegressor()),\n",
    "    (\"Random Forest\", RandomForestRegressor()),\n",
    "    (\"Gradient Boosting\", GradientBoostingRegressor()),\n",
    "    (\"Support Vector Machine\", SVR()),\n",
    "    (\"K-Nearest Neighbors\", KNeighborsRegressor())\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Make predictions\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Store the results\n",
    "    results.append((model_name, mse, r2))\n",
    "\n",
    "# Convert the results to a DataFrame for easy comparison\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"MSE\", \"R-squared\"])\n",
    "\n",
    "# Sort models by MSE (lower is better)\n",
    "results_df = results_df.sort_values(by=\"MSE\", ascending=True)\n",
    "\n",
    "# Print the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test and y_test for merged_df_after_june\n",
    "X_test = merged_df_after_june.drop(columns=columns_to_drop)\n",
    "y_test = merged_df_after_june['fantasy_points']\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# # Transform X_test with the already fitted scaler\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# You can now compare y_pred with y_test to evaluate the model's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to Results/predicted_fantasy_points_odi.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on X_test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a new DataFrame with the necessary columns\n",
    "predictions_df = merged_df_after_june[['match_id', 'player_id', 'player_name', 'fantasy_points', 'role', 'team_name']].copy()\n",
    "\n",
    "# Add the predicted fantasy points to the DataFrame\n",
    "predictions_df['predicted_fantasy_points'] = y_pred\n",
    "\n",
    "# Rename the fantasy_points column to actual_fantasy_points\n",
    "predictions_df.rename(columns={'fantasy_points': 'actual_fantasy_points'}, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = \"Results/predicted_fantasy_points_odi.csv\"  # You can change the file path as needed\n",
    "predictions_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 matches...\n",
      "Processed 200 matches...\n",
      "Processed 300 matches...\n",
      "Processed 400 matches...\n",
      "Processed 500 matches...\n",
      "Processed 600 matches...\n",
      "Dream Team details saved to Results/dream_team_with_predicted_fantasy_points.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input File (Predicted Fantasy Points)\n",
    "input_file = \"Results/predicted_fantasy_points_odi.csv\"\n",
    "\n",
    "# Output File\n",
    "output_file = \"Results/dream_team_with_predicted_fantasy_points.csv\"\n",
    "\n",
    "# Columns for Output\n",
    "output_columns = [\n",
    "    \"match_id\", \"player_id\", \"player_name\", \"actual_fantasy_points\", \"role\", \"team_name\", \"predicted_fantasy_points\"\n",
    "]\n",
    "\n",
    "# Read Data\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Prepare Output Data\n",
    "output_data = []\n",
    "\n",
    "# Define Dream Team Calculation Logic\n",
    "def calculate_dream_team(players):\n",
    "    try:\n",
    "        # Step 1: Pick one player from each role based on predicted fantasy points\n",
    "        selected_players = []\n",
    "        for role in [\"Batsman\", \"Bowler\", \"Wicket-Keeper\", \"All-Rounder\"]:\n",
    "            role_players = [p for p in players if p[\"role\"] == role]\n",
    "            if role_players:\n",
    "                selected_players.append(max(role_players, key=lambda x: x[\"predicted_fantasy_points\"]))\n",
    "\n",
    "        # Step 2: Select remaining players to make a team of 11\n",
    "        remaining_players = [p for p in players if p not in selected_players]\n",
    "        remaining_players.sort(key=lambda x: x[\"predicted_fantasy_points\"], reverse=True)\n",
    "\n",
    "        while len(selected_players) < 11:\n",
    "            next_player = remaining_players.pop(0)\n",
    "            selected_players.append(next_player)\n",
    "\n",
    "        # Step 3: Ensure team diversity (max 5 players from one team)\n",
    "        team_counts = pd.DataFrame(selected_players)[\"team_name\"].value_counts()\n",
    "        if team_counts.max() == 11:\n",
    "            # Replace the lowest fantasy point player with the highest fantasy point player from the other team\n",
    "            other_team = [team for team in players[0][\"team_name\"].unique() if team not in team_counts.index][0]\n",
    "            lowest_fantasy_player = min(selected_players, key=lambda x: x[\"predicted_fantasy_points\"])\n",
    "            replacement_player = max(\n",
    "                [p for p in players if p[\"team_name\"] == other_team and p not in selected_players],\n",
    "                key=lambda x: x[\"predicted_fantasy_points\"]\n",
    "            )\n",
    "            selected_players.remove(lowest_fantasy_player)\n",
    "            selected_players.append(replacement_player)\n",
    "\n",
    "        # Step 4: Sort selected players by predicted fantasy points\n",
    "        selected_players.sort(key=lambda x: x[\"predicted_fantasy_points\"], reverse=True)\n",
    "\n",
    "        return selected_players, \"Optimal\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculating dream team: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "# Process Matches\n",
    "i = 1\n",
    "for match_id, match_group in data.groupby(\"match_id\"):\n",
    "    # Extract only necessary columns (player_id, role, team_name, predicted_fantasy_points)\n",
    "    players = match_group[['match_id', 'player_id', 'player_name', 'actual_fantasy_points', 'role', 'team_name', 'predicted_fantasy_points']].to_dict(orient=\"records\")\n",
    "    \n",
    "    # Calculate Dream Team\n",
    "    selected_team, status = calculate_dream_team(players)\n",
    "\n",
    "    if selected_team is None or len(selected_team) != 11:\n",
    "        # If selected_team is None or doesn't have exactly 11 players, log the error\n",
    "        with open(\"matches_where_team_could_not_be_formed.txt\", 'a') as file:\n",
    "            file.write(f\"{status}, {match_id}, {len(selected_team) if selected_team else 'None'}, {selected_team if selected_team else 'None'}\\n\")\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # Prepare Row for Output\n",
    "    for player in selected_team:\n",
    "        row = [\n",
    "            match_id,\n",
    "            player[\"player_id\"],\n",
    "            player[\"player_name\"],\n",
    "            player[\"actual_fantasy_points\"],\n",
    "            player[\"role\"],\n",
    "            player[\"team_name\"],\n",
    "            player[\"predicted_fantasy_points\"]\n",
    "        ]\n",
    "        output_data.append(row)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i} matches...\")\n",
    "    i += 1\n",
    "\n",
    "# Write Output to CSV\n",
    "output_df = pd.DataFrame(output_data, columns=output_columns)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dream Team details saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 matches...\n",
      "Processed 200 matches...\n",
      "Processed 300 matches...\n",
      "Processed 400 matches...\n",
      "Processed 500 matches...\n",
      "Processed 600 matches...\n",
      "Dream Team details saved to Results/dream_team_with_actual_fantasy_points.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input File (Predicted Fantasy Points)\n",
    "input_file = \"Results/predicted_fantasy_points_odi.csv\"\n",
    "\n",
    "# Output File\n",
    "output_file = \"Results/dream_team_with_actual_fantasy_points.csv\"\n",
    "\n",
    "# Columns for Output\n",
    "output_columns = [\n",
    "    \"match_id\", \"player_id\", \"player_name\", \"actual_fantasy_points\", \"role\", \"team_name\", \"predicted_fantasy_points\"\n",
    "]\n",
    "\n",
    "# Read Data\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Prepare Output Data\n",
    "output_data = []\n",
    "\n",
    "# Define Dream Team Calculation Logic\n",
    "def calculate_dream_team(players):\n",
    "    try:\n",
    "        # Step 1: Pick one player from each role based on predicted fantasy points\n",
    "        selected_players = []\n",
    "        for role in [\"Batsman\", \"Bowler\", \"Wicket-Keeper\", \"All-Rounder\"]:\n",
    "            role_players = [p for p in players if p[\"role\"] == role]\n",
    "            if role_players:\n",
    "                selected_players.append(max(role_players, key=lambda x: x[\"actual_fantasy_points\"]))\n",
    "\n",
    "        # Step 2: Select remaining players to make a team of 11\n",
    "        remaining_players = [p for p in players if p not in selected_players]\n",
    "        remaining_players.sort(key=lambda x: x[\"actual_fantasy_points\"], reverse=True)\n",
    "\n",
    "        while len(selected_players) < 11:\n",
    "            next_player = remaining_players.pop(0)\n",
    "            selected_players.append(next_player)\n",
    "\n",
    "        # Step 3: Ensure team diversity (max 5 players from one team)\n",
    "        team_counts = pd.DataFrame(selected_players)[\"team_name\"].value_counts()\n",
    "        if team_counts.max() == 11:\n",
    "            # Replace the lowest fantasy point player with the highest fantasy point player from the other team\n",
    "            other_team = [team for team in players[0][\"team_name\"].unique() if team not in team_counts.index][0]\n",
    "            lowest_fantasy_player = min(selected_players, key=lambda x: x[\"actual_fantasy_points\"])\n",
    "            replacement_player = max(\n",
    "                [p for p in players if p[\"team_name\"] == other_team and p not in selected_players],\n",
    "                key=lambda x: x[\"actual_fantasy_points\"]\n",
    "            )\n",
    "            selected_players.remove(lowest_fantasy_player)\n",
    "            selected_players.append(replacement_player)\n",
    "\n",
    "        # Step 4: Sort selected players by actual fantasy points\n",
    "        selected_players.sort(key=lambda x: x[\"actual_fantasy_points\"], reverse=True)\n",
    "\n",
    "        return selected_players, \"Optimal\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculating dream team: {e}\")\n",
    "        return None, \"Error\"\n",
    "\n",
    "# Process Matches\n",
    "i = 1\n",
    "for match_id, match_group in data.groupby(\"match_id\"):\n",
    "    # Extract only necessary columns (player_id, role, team_name, predicted_fantasy_points)\n",
    "    players = match_group[['match_id', 'player_id', 'player_name', 'actual_fantasy_points', 'role', 'team_name', 'predicted_fantasy_points']].to_dict(orient=\"records\")\n",
    "    \n",
    "    # Calculate Dream Team\n",
    "    selected_team, status = calculate_dream_team(players)\n",
    "\n",
    "    if selected_team is None or len(selected_team) != 11:\n",
    "        # If selected_team is None or doesn't have exactly 11 players, log the error\n",
    "        with open(\"matches_where_team_could_not_be_formed.txt\", 'a') as file:\n",
    "            file.write(f\"{status}, {match_id}, {len(selected_team) if selected_team else 'None'}, {selected_team if selected_team else 'None'}\\n\")\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # Prepare Row for Output\n",
    "    for player in selected_team:\n",
    "        row = [\n",
    "            match_id,\n",
    "            player[\"player_id\"],\n",
    "            player[\"player_name\"],\n",
    "            player[\"actual_fantasy_points\"],\n",
    "            player[\"role\"],\n",
    "            player[\"team_name\"],\n",
    "            player[\"predicted_fantasy_points\"]\n",
    "        ]\n",
    "        output_data.append(row)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i} matches...\")\n",
    "    i += 1\n",
    "\n",
    "# Write Output to CSV\n",
    "output_df = pd.DataFrame(output_data, columns=output_columns)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dream Team details saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARISION OF ACTUAL AND PREDICTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to Results/dream_team_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths for the input files\n",
    "predicted_file = \"Results/dream_team_with_predicted_fantasy_points.csv\"\n",
    "actual_file = \"Results/dream_team_with_actual_fantasy_points.csv\"\n",
    "\n",
    "# Output file path\n",
    "output_file = \"Results/dream_team_summary.csv\"\n",
    "\n",
    "# Read the data from the two files\n",
    "predicted_df = pd.read_csv(predicted_file)\n",
    "actual_df = pd.read_csv(actual_file)\n",
    "\n",
    "# Initialize list to store the summary for each match_id\n",
    "summary_data = []\n",
    "\n",
    "# Function to calculate the sum of fantasy points (with captain and vice-captain multipliers)\n",
    "def calculate_team_points(team_df):\n",
    "    team_df = team_df.sort_values(by='predicted_fantasy_points', ascending=False)  # Sort by predicted points (or actual, depending on case)\n",
    "    \n",
    "    total_points = 0\n",
    "    if len(team_df) >= 1:\n",
    "        # Highest points player (Captain)\n",
    "        total_points += team_df.iloc[0]['predicted_fantasy_points'] * 2\n",
    "    if len(team_df) >= 2:\n",
    "        # Second highest points player (Vice-Captain)\n",
    "        total_points += team_df.iloc[1]['predicted_fantasy_points'] * 1.5\n",
    "    \n",
    "    # Add the rest normally\n",
    "    total_points += team_df.iloc[2:]['predicted_fantasy_points'].sum()\n",
    "\n",
    "    return total_points\n",
    "\n",
    "# Iterate through the unique match IDs\n",
    "for match_id in predicted_df['match_id'].unique():\n",
    "    # Get the predicted dream team for the current match_id\n",
    "    predicted_team = predicted_df[predicted_df['match_id'] == match_id]\n",
    "\n",
    "    # Get the actual dream team for the current match_id\n",
    "    actual_team = actual_df[actual_df['match_id'] == match_id]\n",
    "\n",
    "    # Calculate the sum of actual and predicted points for both teams\n",
    "    predicted_team_points = calculate_team_points(predicted_team)\n",
    "    actual_team_points_predicted = calculate_team_points(actual_team)\n",
    "    \n",
    "    # Add the match summary to the summary_data list\n",
    "    summary_data.append({\n",
    "        'match_id': match_id,\n",
    "        'sum_predicted_points_predicted_team': predicted_team_points,\n",
    "        'sum_predicted_points_actual_team': actual_team_points_predicted,\n",
    "        'sum_actual_points_predicted_team': predicted_team['actual_fantasy_points'].sum(),\n",
    "        'sum_actual_points_actual_team': actual_team['actual_fantasy_points'].sum()\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the summary_data\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Write the summary data to a CSV file\n",
    "summary_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Summary saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Errors for each match:\n",
      "     match_id  %error_predicted_actual  %error_predicted_predicted\n",
      "0     1385697                30.870083                   45.056579\n",
      "1     1385698                48.484848                   45.308186\n",
      "2     1398277                19.202363                   24.346644\n",
      "3     1398278                40.661939                   20.121403\n",
      "4     1398279                38.253968                   23.958959\n",
      "..        ...                      ...                         ...\n",
      "615   1457354                28.293413                   40.004281\n",
      "616   1457355                26.655629                   34.640239\n",
      "617   1457356                10.915493                   31.198942\n",
      "618   1457357                12.267658                   26.165084\n",
      "619   1457358                19.305019                   20.156410\n",
      "\n",
      "[620 rows x 3 columns]\n",
      "\n",
      "Mean % error between predicted team actual points and actual team actual points: 31.71%\n",
      "Mean % error between predicted team predicted points and actual team actual points: 32.96%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dream_team_summary.csv file into a DataFrame\n",
    "summary_file = \"Results/dream_team_summary.csv\"\n",
    "df = pd.read_csv(summary_file)\n",
    "\n",
    "# Calculate the percentage errors for each match\n",
    "df['%error_predicted_actual'] = abs(df['sum_actual_points_predicted_team'] - df['sum_actual_points_actual_team']) / df['sum_actual_points_actual_team'] * 100\n",
    "df['%error_predicted_predicted'] = abs(df['sum_predicted_points_predicted_team'] - df['sum_actual_points_actual_team']) / df['sum_actual_points_actual_team'] * 100\n",
    "\n",
    "# Print the results with the percentage errors\n",
    "print(\"Percentage Errors for each match:\")\n",
    "print(df[['match_id', '%error_predicted_actual', '%error_predicted_predicted']])\n",
    "\n",
    "# Calculate the mean of the percentage errors\n",
    "mean_error_predicted_actual = df['%error_predicted_actual'].mean()\n",
    "mean_error_predicted_predicted = df['%error_predicted_predicted'].mean()\n",
    "\n",
    "# Print the mean errors\n",
    "print(f\"\\nMean % error between predicted team actual points and actual team actual points: {mean_error_predicted_actual:.2f}%\")\n",
    "print(f\"Mean % error between predicted team predicted points and actual team actual points: {mean_error_predicted_predicted:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Errors for each match:\n",
      "     match_id  %error_predicted_actual  %error_predicted_predicted\n",
      "0     1385697                30.870083                   45.056579\n",
      "1     1385698                48.484848                   45.308186\n",
      "2     1398277                19.202363                   24.346644\n",
      "3     1398278                40.661939                   20.121403\n",
      "4     1398279                38.253968                   23.958959\n",
      "..        ...                      ...                         ...\n",
      "615   1457354                28.293413                   40.004281\n",
      "616   1457355                26.655629                   34.640239\n",
      "617   1457356                10.915493                   31.198942\n",
      "618   1457357                12.267658                   26.165084\n",
      "619   1457358                19.305019                   20.156410\n",
      "\n",
      "[620 rows x 3 columns]\n",
      "\n",
      "Mean % error between predicted team actual points and actual team actual points: 31.71%\n",
      "Mean % error between predicted team predicted points and actual team actual points: 32.96%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dream_team_summary.csv file into a DataFrame\n",
    "summary_file = \"Results/dream_team_summary.csv\"\n",
    "df = pd.read_csv(summary_file)\n",
    "\n",
    "# Calculate the percentage errors for each match\n",
    "df['%error_predicted_actual'] = abs(df['sum_actual_points_predicted_team'] - df['sum_actual_points_actual_team']) / df['sum_actual_points_actual_team'] * 100\n",
    "df['%error_predicted_predicted'] = abs(df['sum_predicted_points_predicted_team'] - df['sum_actual_points_actual_team']) / df['sum_actual_points_actual_team'] * 100\n",
    "\n",
    "# Calculate the mean of the percentage errors\n",
    "mean_error_predicted_actual = df['%error_predicted_actual'].mean()\n",
    "mean_error_predicted_predicted = df['%error_predicted_predicted'].mean()\n",
    "\n",
    "# Print the results with the percentage errors\n",
    "print(\"Percentage Errors for each match:\")\n",
    "print(df[['match_id', '%error_predicted_actual', '%error_predicted_predicted']])\n",
    "\n",
    "# Print the mean errors\n",
    "print(f\"\\nMean % error between predicted team actual points and actual team actual points: {mean_error_predicted_actual:.2f}%\")\n",
    "print(f\"Mean % error between predicted team predicted points and actual team actual points: {mean_error_predicted_predicted:.2f}%\")\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(summary_file, index=False)\n",
    "\n",
    "# Optionally, save to a new file if you don't want to overwrite the original\n",
    "# df.to_csv(\"Results/dream_team_summary_with_errors.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_t20.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'model_t20.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
